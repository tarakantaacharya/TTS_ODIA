{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarakantaacharya/TTS_ODIA/blob/main/Preprocessing_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er1AoufPKwwD",
        "outputId": "029259bc-6305-4c4c-f582-fe9fe83f8095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets\n",
        "! pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsMgpqZ3K44B",
        "outputId": "cb73604a-5c0c-47f7-a1f3-69be8f2a644a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvTLjGWvKxWO",
        "outputId": "369706f9-268d-4bbf-9d54-7105f56c82d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 50 rows out of 11564\n",
            "Processed 100 rows out of 11564\n",
            "Processed 150 rows out of 11564\n",
            "Processed 200 rows out of 11564\n",
            "Processed 250 rows out of 11564\n",
            "Processed 300 rows out of 11564\n",
            "Processed 350 rows out of 11564\n",
            "Processed 400 rows out of 11564\n",
            "Processed 450 rows out of 11564\n",
            "Processed 500 rows out of 11564\n",
            "Processed 550 rows out of 11564\n",
            "Processed 600 rows out of 11564\n",
            "Processed 650 rows out of 11564\n",
            "Processed 700 rows out of 11564\n",
            "Processed 750 rows out of 11564\n",
            "Processed 800 rows out of 11564\n",
            "Processed 850 rows out of 11564\n",
            "Processed 900 rows out of 11564\n",
            "Processed 950 rows out of 11564\n",
            "Processed 1000 rows out of 11564\n",
            "Processed 1050 rows out of 11564\n",
            "Processed 1100 rows out of 11564\n",
            "Data has been saved to processed_data.json.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "import librosa\n",
        "\n",
        "# Function to preprocess the audio (example: resample and normalize)\n",
        "def preprocess_audio(audio_data, sampling_rate, target_sr=16000):\n",
        "    # Resample the audio to a target sample rate (if needed)\n",
        "    if sampling_rate != target_sr:\n",
        "        audio_data = librosa.resample(audio_data, orig_sr=sampling_rate, target_sr=target_sr)  # Corrected\n",
        "        sampling_rate = target_sr  # Update the sampling rate to target\n",
        "\n",
        "    # Normalize the audio (scaling the waveform between -1 and 1)\n",
        "    audio_data = librosa.util.normalize(audio_data)\n",
        "\n",
        "    return audio_data, sampling_rate\n",
        "\n",
        "# Function to preprocess the text (tokenize)\n",
        "def preprocess_text(text, tokenizer):\n",
        "    # Tokenize the text into input IDs\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\")\n",
        "    return tokens['input_ids'].squeeze(0).tolist()  # Get tokenized text as list of IDs\n",
        "\n",
        "# Function to preprocess data from the dataset\n",
        "def preprocess_data_from_dataset(dataset, index, tokenizer):\n",
        "    # Extract the audio data and sampling rate\n",
        "    audio_data = dataset[index]['audio']['array']\n",
        "    sampling_rate = dataset[index]['audio']['sampling_rate']\n",
        "\n",
        "    # Preprocess the audio\n",
        "    norm_audio_data, processed_sr = preprocess_audio(audio_data, sampling_rate)\n",
        "\n",
        "    # Preprocess the text\n",
        "    text = dataset[index]['text']\n",
        "    tokenized_text = preprocess_text(text, tokenizer)\n",
        "\n",
        "    # Return the preprocessed audio and tokenized text\n",
        "    return norm_audio_data.tolist(), tokenized_text\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"SPRINGLab/IndicTTS_Odia\")\n",
        "\n",
        "# Load the tokenizer for the language model\n",
        "tokenizer = tokenizer\n",
        "\n",
        "processed_data = []\n",
        "\n",
        "batch_size = 50  # Load 50 rows at a time\n",
        "\n",
        "# Iterate over dataset in batches of 50\n",
        "for i in range(0, len(dataset['train'])//11, batch_size):\n",
        "    batch = dataset['train'].select(range(i, min(i + batch_size, len(dataset['train']))))  # Select batch\n",
        "\n",
        "    for example in batch:\n",
        "        norm_audio_data, tokenized_text = preprocess_data_from_dataset(batch, 0, tokenizer)\n",
        "\n",
        "        processed_data.append({\n",
        "            \"audio\": norm_audio_data,\n",
        "            \"text\": tokenized_text\n",
        "        })\n",
        "\n",
        "    print(f\"Processed {min(i + batch_size, len(dataset['train']))} rows out of {len(dataset['train'])}\")\n",
        "\n",
        "# Store the processed data as a JSON file\n",
        "with open(\"processed_data.json\", \"w\") as json_file:\n",
        "    json.dump(processed_data, json_file)\n",
        "\n",
        "print(\"Data has been saved to processed_data.json.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaT-3r-zTTXf",
        "outputId": "320fd0e2-6645-43c7-ad42-9e4c83bd7aae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1100"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_json('processed_data.json')\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRXVS7TSUX_B",
        "outputId": "767a17ef-920e-44d7-f6a4-5bf3d3f304cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(47226,)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.array(df.iloc[0]['audio']).shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example array\n",
        "array_data = np.array(df.iloc[0]['audio'])\n",
        "\n",
        "# Count the number of zeros\n",
        "num_zeros = np.count_nonzero(array_data == 0)\n",
        "\n",
        "# Count the number of non-zero elements\n",
        "num_non_zeros = array_data.size - num_zeros  # Total size - zeros\n",
        "\n",
        "print(f\"Number of zeros: {num_zeros}\")\n",
        "print(f\"Number of non-zero elements: {num_non_zeros}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsnslebHW_Ah",
        "outputId": "21aea752-ca16-4974-e1f7-f44306b6b479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of zeros: 9119\n",
            "Number of non-zero elements: 38107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqidhcsUcFHE",
        "outputId": "21ee3e26-6b26-457b-f520-12f473072d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['audio', 'text'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(df['audio']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkhJI7GocM-p",
        "outputId": "71120a6d-f1c0-4806-a6b4-0fdf1d42cf70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(df['text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0bm2ERKcUM7",
        "outputId": "777c3a04-221c-43ff-9320-896df6eb991a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0TxA3facu5o",
        "outputId": "b94e0919-0069-4300-d3cb-3837cbee2af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "text     [2, 41, 62688, 1, 41, 1, 62827, 62008, 1, 6267...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLw16GpLdGYi",
        "outputId": "d6d9abcd-32af-4ba8-cbf6-99071ec4f001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               audio  \\\n",
            "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
            "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
            "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
            "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
            "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
            "\n",
            "                                                text  \n",
            "0  [2, 41, 62688, 1, 41, 1, 62827, 62008, 1, 6267...  \n",
            "1  [2, 41, 62688, 1, 41, 1, 62827, 62008, 1, 6267...  \n",
            "2  [2, 41, 62688, 1, 41, 1, 62827, 62008, 1, 6267...  \n",
            "3  [2, 41, 62688, 1, 41, 1, 62827, 62008, 1, 6267...  \n",
            "4  [2, 41, 62688, 1, 41, 1, 62827, 62008, 1, 6267...  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6QgiuKfAJMJsHnTwDWNTU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}